# Classifica√ß√£o de Imagens: Gatos vs. Cachorros com Redes Neurais

Este projeto explora e compara diferentes arquiteturas de redes neurais para a tarefa de classifica√ß√£o de imagens, distinguindo entre gatos e cachorros. A an√°lise parte de um modelo simples (MLP) como linha de base, avan√ßa para Redes Neurais Convolucionais (CNNs) customizadas e culmina no uso de t√©cnicas de *Transfer Learning* com os modelos VGG16 e MobileNetV2.

## üìù Descri√ß√£o do Projeto

O objetivo principal √© demonstrar a efic√°cia das Redes Neurais Convolucionais (CNNs) em tarefas de vis√£o computacional em compara√ß√£o com uma Rede Neural Multilayer Perceptron (MLP) tradicional. O notebook detalha cada passo, desde a prepara√ß√£o dos dados at√© o treinamento e a compara√ß√£o final de desempenho entre os modelos.

## üíø Dataset

O projeto utiliza o dataset "Cats and Dogs" da Microsoft, disponibilizado publicamente pelo Kaggle. O conjunto de dados cont√©m 25.000 imagens (12.500 de cada classe).

O notebook automatiza as seguintes etapas de prepara√ß√£o:
1.  **Download:** Baixa o arquivo `.zip` diretamente da fonte.
2.  **Organiza√ß√£o:** Descompacta e estrutura os arquivos em diret√≥rios de `treino` (80%) e `validacao` (20%), mantendo as classes (gatos/caes) separadas.
3.  **Limpeza de Dados:** Arquivos corrompidos ou inv√°lidos s√£o identificados e removidos do conjunto de dados para garantir que o treinamento ocorra sem interrup√ß√µes.

## üõ†Ô∏è Estrutura do Projeto

O fluxo de trabalho no notebook `CNNS.ipynb` est√° organizado da seguinte forma:

1.  **Prepara√ß√£o do Ambiente:** Importa√ß√£o das bibliotecas necess√°rias, como TensorFlow, Keras, NumPy, e Matplotlib.
2.  **Cria√ß√£o do Dataset:** Download, extra√ß√£o e organiza√ß√£o do conjunto de dados de imagens.
3.  **Limpeza e Pipeline de Dados:** Verifica√ß√£o de integridade das imagens com TensorFlow e cria√ß√£o de um pipeline de dados eficiente com `tf.data` para alimentar os modelos durante o treinamento.
4.  **Modelagem e Treinamento:**
    * **Rede MLP (Baseline):** Uma rede neural densa simples √© criada e treinada para estabelecer uma acur√°cia de base.
    * **CNNs Customizadas:** Quatro arquiteturas de CNNs s√£o constru√≠das e treinadas, variando o tamanho do kernel (3x3 vs. 5x5) e a profundidade da rede para analisar o impacto dessas mudan√ßas.
    * **Transfer Learning (VGG16 e MobileNetV2):** Dois modelos pr√©-treinados famosos s√£o utilizados como extratores de caracter√≠sticas. Suas camadas convolucionais s√£o "congeladas" e novas camadas de classifica√ß√£o s√£o adicionadas e treinadas com os dados do projeto.
5.  **An√°lise Comparativa:** Os resultados de acur√°cia, n√∫mero de par√¢metros e a matriz de confus√£o dos modelos mais perform√°ticos s√£o comparados para extrair conclus√µes.

## üöÄ Modelos Desenvolvidos

-   **MLP (Baseline):** Uma rede com uma camada de achatamento (`Flatten`) seguida por duas camadas densas (`Dense`). Serviu para mostrar as limita√ß√µes de uma abordagem que n√£o considera a estrutura espacial das imagens.
-   **CNN 1 e 3 (Kernel 3x3):** Redes convolucionais com 3 e 4 camadas `Conv2D`, respectivamente, usando filtros de tamanho 3x3.
-   **CNN 2 e 4 (Kernel 5x5):** Arquiteturas similares √†s anteriores, mas com filtros de 5x5 para capturar padr√µes espaciais maiores.
-   **Transfer Learning com VGG16:** Utiliza a base convolucional do modelo VGG16, conhecido por sua profundidade e efic√°cia, mas com um alto n√∫mero de par√¢metros.
-   **Transfer Learning com MobileNetV2:** Utiliza a base do MobileNetV2, uma arquitetura otimizada para efici√™ncia, com significativamente menos par√¢metros.

## üìä Resultados

A compara√ß√£o final demonstrou a clara superioridade das abordagens baseadas em convolu√ß√µes para o problema.

| Modelo                          | Acur√°cia de Valida√ß√£o | Par√¢metros Trein√°veis |
| :------------------------------ | :-------------------- | :-------------------- |
| MLP (Baseline)                  | ~63.4%                | 6,299,905             |
| CNN (Customizada - 5x5)         | ~84.5%                | 456,705               |
| VGG16 (Transfer Learning)       | ~88.8%                | 131,585               |
| **MobileNetV2 (Transfer Learning)** | **~97.0%** | **328,193** |

### Conclus√£o
-   A **MLP** teve o pior desempenho e o maior n√∫mero de par√¢metros, pois ao "achatar" a imagem, perde toda a informa√ß√£o espacial, que √© crucial para a an√°lise.
-   As **CNNs customizadas** superaram a MLP com folga e com muito menos par√¢metros, provando a efici√™ncia das camadas convolucionais. O kernel 5x5 se mostrou ligeiramente superior para este problema.
-   O **Transfer Learning** obteve os melhores resultados. O **MobileNetV2** foi o grande destaque, alcan√ßando a maior acur√°cia (**~97%**) com um n√∫mero de par√¢metros significativamente menor que o da MLP, demonstrando ser um modelo extremamente eficiente e poderoso.

## Como Executar

1.  **Ambiente:** O notebook foi desenvolvido para ser executado em ambientes como Google Colab ou Jupyter Notebook com GPU.
2.  **Depend√™ncias:** Certifique-se de ter as principais bibliotecas instaladas:
    ```bash
    pip install tensorflow numpy pandas matplotlib seaborn scikit-learn
    ```
3.  **Execu√ß√£o:** Abra o arquivo `CNNS.ipynb` e execute as c√©lulas em ordem sequencial. O download e a prepara√ß√£o dos dados s√£o feitos automaticamente pelo c√≥digo.
